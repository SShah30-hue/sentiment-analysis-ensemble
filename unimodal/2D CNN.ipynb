{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471ffe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import (EarlyStopping, LearningRateScheduler,\n",
    "                             ModelCheckpoint, TensorBoard, ReduceLROnPlateau)\n",
    "from keras import losses, models\n",
    "from keras.activations import relu, softmax\n",
    "from keras.layers import (Convolution2D, GlobalAveragePooling2D, BatchNormalization, Flatten, Dropout,\n",
    "                          GlobalMaxPool2D, MaxPool2D, concatenate, Activation, Input, Dense)\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "import scipy\n",
    "from scipy.stats import skew\n",
    "import librosa\n",
    "import librosa.display\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob \n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import IPython.display as ipd \n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "import csv\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a806f89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7fa060",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'C:/Data/Sentiment Analysis/MELD/Processed/Processed_final/v4/train.csv')\n",
    "dev =  pd.read_csv(r'C:/Data/Sentiment Analysis/MELD/Processed/Processed_final/v4/dev.csv')\n",
    "test =  pd.read_csv(r'C:/Data/Sentiment Analysis/MELD/Processed/Processed_final/v4/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c5c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train))\n",
    "print(len(dev))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021551e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [train,test]\n",
    "MELD_df = pd.concat(dfs, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3656356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(MELD_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163018af",
   "metadata": {},
   "outputs": [],
   "source": [
    "MELD_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d1542",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "1. Extracting the MFCC feature as an image (Matrix format).  \n",
    "'''\n",
    "def prepare_data(df, n, mfcc):\n",
    "    X = np.empty(shape=(MELD_df.shape[0], n, 1282, 1))\n",
    "    input_length = sampling_rate * audio_duration\n",
    "    \n",
    "    cnt = 0\n",
    "    for fname in tqdm(MELD_df.path):\n",
    "        file_path = fname\n",
    "        data, _ = librosa.load(file_path, sr=sampling_rate\n",
    "                               ,res_type=\"kaiser_fast\"\n",
    "                               ,duration=41\n",
    "                               ,offset=0.0\n",
    "                              )\n",
    "\n",
    "        # Random offset / Padding\n",
    "        if len(data) > input_length:\n",
    "            max_offset = len(data) - input_length\n",
    "            offset = np.random.randint(max_offset)\n",
    "            data = data[offset:(input_length+offset)]\n",
    "        else:\n",
    "            if input_length > len(data):\n",
    "                max_offset = input_length - len(data)\n",
    "                offset = np.random.randint(max_offset)\n",
    "            else:\n",
    "                offset = 0\n",
    "            data = np.pad(data, (offset, int(input_length) - len(data) - offset), \"constant\")\n",
    "        \n",
    "        # which feature?\n",
    "        if mfcc == 1:\n",
    "            # MFCC extraction \n",
    "            MFCC = librosa.feature.mfcc(data, sr=sampling_rate, n_mfcc=n_mfcc)\n",
    "            MFCC = np.expand_dims(MFCC, axis=-1)\n",
    "            X[cnt,] = MFCC\n",
    "            \n",
    "        else:\n",
    "            # Log-melspectogram\n",
    "            melspec = librosa.feature.melspectrogram(data, n_mels = n_melspec)   \n",
    "            logspec = librosa.amplitude_to_db(melspec)\n",
    "            logspec = np.expand_dims(logspec, axis=-1)\n",
    "            X[cnt,] = logspec\n",
    "            \n",
    "        cnt += 1\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "'''\n",
    "2. Confusion matrix plot \n",
    "'''        \n",
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
    "    '''Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    '''\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    \n",
    "    \n",
    "'''\n",
    "# 3. Create the 2D CNN model \n",
    "'''\n",
    "def get_2d_conv_model(n):\n",
    "    ''' Create a standard deep 2D convolutional neural network'''\n",
    "    nclass = 3\n",
    "    inp = Input(shape=(n,1282, 1))  #2D matrix of 30 MFCC bands by xxx audio length.\n",
    "    x = Convolution2D(32, (4,10), padding=\"same\")(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    out = Dense(nclass, activation=softmax)(x)\n",
    "    \n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    opt = Adam(0.001) #optimizer= \"adam\"\n",
    "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc']) \n",
    "    return model\n",
    "\n",
    "'''\n",
    "# 4. Other functions \n",
    "'''\n",
    "class get_results:\n",
    "    '''\n",
    "    We're going to create a class (blueprint template) for generating the results based on the various model approaches. \n",
    "    So instead of repeating the functions each time, we assign the results into on object with its associated variables \n",
    "    depending on each combination:\n",
    "        1) MFCC with no augmentation  \n",
    "        2) MFCC with augmentation \n",
    "        3) Logmelspec with no augmentation \n",
    "        4) Logmelspec with augmentation\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, model_history, model ,X_test, y_test, labels):\n",
    "        self.model_history = model_history\n",
    "        self.model = model\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test             \n",
    "        self.labels = labels\n",
    "\n",
    "    def create_plot(self, model_history):\n",
    "        '''Check the logloss of both train and validation, make sure they are close and have plateau'''\n",
    "        plt.plot(model_history.history['loss'])\n",
    "        plt.plot(model_history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "    def create_results(self, model):\n",
    "        '''predict on test set and get accuracy results'''\n",
    "        opt = Adam(0.001) #optimizer= \"adam\"\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "        score = model.evaluate(X_test, y_test, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "    def confusion_results(self, X_test, y_test, labels, model):\n",
    "        '''plot confusion matrix results'''\n",
    "        preds = model.predict(X_test, \n",
    "                                 batch_size=16, \n",
    "                                 verbose=2)\n",
    "        preds= preds.argmax(axis=1)\n",
    "        preds = preds.astype(int).flatten()\n",
    "        preds = (lb.inverse_transform((preds)))\n",
    "\n",
    "        actual = y_test.argmax(axis=1)\n",
    "        actual = actual.astype(int).flatten()\n",
    "        actual = (lb.inverse_transform((actual)))\n",
    "\n",
    "        classes = labels\n",
    "        classes.sort()    \n",
    "\n",
    "        c = confusion_matrix(actual, preds)\n",
    "        print_confusion_matrix(c, class_names = classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b9a34c",
   "metadata": {},
   "source": [
    "## MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a06fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate=16000\n",
    "audio_duration=41\n",
    "n_mfcc = 30\n",
    "mfcc = prepare_data(MELD_df.path, n = n_mfcc, mfcc = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1f77cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split between train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(mfcc\n",
    "                                                    , MELD_df.sentiment\n",
    "                                                    , train_size=9988\n",
    "                                                    , test_size=2608\n",
    "                                                    , shuffle=False\n",
    "                                                   )\n",
    "\n",
    "\n",
    "# one hot encode the target \n",
    "lb = LabelEncoder()\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n",
    "\n",
    "# Normalization as per the standard NN process\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "\n",
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std\n",
    "\n",
    "# Build CNN model\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    model = get_2d_conv_model(n=n_mfcc)\n",
    "    model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                              batch_size=16, verbose = 2, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e55a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9076c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_results(model_history,model,X_test,y_test, MELD_df.sentiment.unique())\n",
    "results.create_plot(model_history)\n",
    "results.create_results(model)\n",
    "results.confusion_results(X_test, y_test, MELD_df.sentiment.unique(), model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe12dd1",
   "metadata": {},
   "source": [
    "### Storing predictions  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a694b849",
   "metadata": {},
   "source": [
    "### For test: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649704b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_name_mapping = dict(zip(lb.classes_, lb.transform(lb.classes_)))\n",
    "print(lb_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7517ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = model.predict(X_test)\n",
    "preds_test1 = preds_test.argmax(axis=1).tolist()\n",
    "actual_test = y_test.argmax(axis=1).tolist()        \n",
    "fileID = test.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1476a6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = { \"fileID_mfcc\": [], \"Negative_mfcc\" : [], \"Neutral_mfcc\" : [], \"Positive_mfcc\" : [], \"predicted_mfcc\": [], \"actual_mfcc\": []}\n",
    "\n",
    "for i in preds_test:\n",
    "\n",
    "    test_predictions[\"Negative_mfcc\"].append(i[0])\n",
    "    test_predictions[\"Neutral_mfcc\"].append(i[1])\n",
    "    test_predictions[\"Positive_mfcc\"].append(i[2])\n",
    "    \n",
    "for i in preds_test1:\n",
    "    \n",
    "    test_predictions[\"predicted_mfcc\"].append(i)\n",
    "    \n",
    "for i in actual_test:\n",
    "    \n",
    "    test_predictions[\"actual_mfcc\"].append(i)\n",
    "    \n",
    "for i in test[\"name\"]:\n",
    "\n",
    "    test_predictions[\"fileID_mfcc\"].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77247f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=test_predictions)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372c6d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving to csv\n",
    "df.to_csv(r\"C:\\Data\\Sentiment Analysis\\MELD\\ensemble preds\\2d_cnn\\v3\\test_mfcc_preds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02779ec5",
   "metadata": {},
   "source": [
    "## Mel spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970a331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate=16000\n",
    "audio_duration=41\n",
    "n_melspec = 60\n",
    "specgram = prepare_data(MELD_df, n = n_melspec, mfcc = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb72ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split between train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(specgram\n",
    "                                                    , MELD_df.sentiment\n",
    "                                                    , train_size=9988\n",
    "                                                    , test_size=2608\n",
    "                                                    , shuffle=False\n",
    "                                                   )\n",
    "\n",
    "# one hot encode the target \n",
    "lb = LabelEncoder()\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n",
    "\n",
    "# Normalization as per the standard NN process\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "\n",
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std\n",
    "\n",
    "# Build CNN model \n",
    "with tf.device(\"/gpu:0\"):\n",
    "    model = get_2d_conv_model(n=n_melspec)\n",
    "    model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                              batch_size=16, verbose = 2, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406b6a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_results(model_history,model,X_test,y_test, MELD_df.sentiment.unique())\n",
    "results.create_plot(model_history)\n",
    "results.create_results(model)\n",
    "results.confusion_results(X_test, y_test, MELD_df.sentiment.unique(), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726331b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c630be0f",
   "metadata": {},
   "source": [
    "### Storing predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd41424",
   "metadata": {},
   "source": [
    "### For test: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c248f47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_name_mapping = dict(zip(lb.classes_, lb.transform(lb.classes_)))\n",
    "print(lb_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3e1241",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = model.predict(X_test)\n",
    "preds_test1 = preds_test.argmax(axis=1).tolist()\n",
    "#preds_test = (lb.inverse_transform((preds_test)))\n",
    "\n",
    "actual_test = y_test.argmax(axis=1).tolist()\n",
    "#actual_test = (lb.inverse_transform((actual_test)))\n",
    "        \n",
    "fileID = test.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0888e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = { \"fileID_specgram\": [], \"Negative_specgram\" : [], \"Neutral_specgram\" : [], \"Positive_specgram\" : [], \"predicted_specgram\": [], \"actual_specgram\": []}\n",
    "\n",
    "for i in preds_test:\n",
    "\n",
    "    test_predictions[\"Negative_specgram\"].append(i[0])\n",
    "    test_predictions[\"Neutral_specgram\"].append(i[1])\n",
    "    test_predictions[\"Positive_specgram\"].append(i[2])\n",
    "    \n",
    "for i in preds_test1:\n",
    "    \n",
    "    test_predictions[\"predicted_specgram\"].append(i)\n",
    "    \n",
    "for i in actual_test:\n",
    "    \n",
    "    test_predictions[\"actual_specgram\"].append(i)\n",
    "    \n",
    "for i in test[\"name\"]:\n",
    "\n",
    "    test_predictions[\"fileID_specgram\"].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4c4f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=test_predictions)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ced6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving to csv\n",
    "df.to_csv(r\"C:\\Data\\Sentiment Analysis\\MELD\\ensemble preds\\2d_cnn\\v3\\test_specgram_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c1e114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda env:.conda-GoogleSTT]",
   "language": "python",
   "name": "conda-env-.conda-GoogleSTT-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
