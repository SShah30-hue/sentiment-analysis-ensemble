{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaModel, RobertaTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchmetrics import AUROC\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.metrics.functional import accuracy, f1, auroc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "pl.seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the data here = https://affective-meld.github.io/\n",
    "df_train_final = pd.read_csv(r\"C:/Data/Sentiment Analysis/MELD/Processed/Processed_final/v2/train.csv\") #please put your path\n",
    "df_dev_final = pd.read_csv(r\"C:/Data/Sentiment Analysis/MELD/Processed/Processed_final/v2/dev.csv\") #please put your path\n",
    "df_test_final = pd.read_csv(r\"C:/Data/Sentiment Analysis/MELD/Processed/Processed_final/v2/test.csv\") #please put your path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train_final.shape, df_dev_final.shape,df_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final['sentiment'] = df_train_final['sentiment'].astype('category')\n",
    "encode_map = {'negative': 0,'neutral': 1,'positive': 2}\n",
    "df_train_final['sentiment'].replace(encode_map, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_final['sentiment'] = df_dev_final['sentiment'].astype('category')\n",
    "encode_map = {'negative': 0,'neutral': 1,'positive': 2}\n",
    "df_dev_final['sentiment'].replace(encode_map, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_final['sentiment'] = df_test_final['sentiment'].astype('category')\n",
    "encode_map = {'negative': 0,'neutral': 1,'positive': 2}\n",
    "df_test_final['sentiment'].replace(encode_map, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final = df_train_final[[\"name\",\"transcription\",\"sentiment\"]]\n",
    "df_test_final = df_test_final[[\"name\",\"transcription\",\"sentiment\"]]\n",
    "df_dev_final = df_dev_final[[\"name\",\"transcription\",\"sentiment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final = df_train_final.rename(columns={\"name\": \"file_ID\"})\n",
    "df_dev_final = df_dev_final.rename(columns={\"name\": \"file_ID\"})\n",
    "df_test_final = df_test_final.rename(columns={\"name\": \"file_ID\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_train_final, df_dev_final, df_test_final]\n",
    "combine = pd.concat(frames)\n",
    "all_data = combine.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head(5) #neg=0, neu=1, pos=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_COLUMNS = all_data.columns.tolist()[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKEN_COUNT = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'roberta-base'\n",
    "tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        tokenizer: RobertaTokenizer,\n",
    "        max_token_len: int = 60\n",
    "    ):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        data_row = self.data.iloc[index]\n",
    "        \n",
    "        Utterance = data_row.transcription\n",
    "        labels = data_row[LABEL_COLUMNS] ##all\n",
    "        fileID = data_row.file_ID\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            Utterance,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_token_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        return dict(\n",
    "            Utterance=Utterance,\n",
    "            input_ids=encoding[\"input_ids\"].flatten(),\n",
    "            attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "            labels=torch.LongTensor(labels),\n",
    "            FileID=fileID\n",
    "\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, df_train_final, df_test_final, df_dev_final, tokenizer, batch_size=16, max_token_len=60):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_df = df_train_final\n",
    "        self.test_df = df_test_final\n",
    "        self.dev_df = df_dev_final\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = Dataset(\n",
    "          self.train_df,\n",
    "          self.tokenizer,\n",
    "          self.max_token_len\n",
    "        )\n",
    "\n",
    "        self.dev_dataset = Dataset(\n",
    "          self.dev_df,\n",
    "          self.tokenizer,\n",
    "          self.max_token_len\n",
    "        )\n",
    "        \n",
    "        self.test_dataset = Dataset(\n",
    "          self.test_df,\n",
    "          self.tokenizer,\n",
    "          self.max_token_len\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "          self.train_dataset,\n",
    "          batch_size=self.batch_size,\n",
    "          shuffle=True,\n",
    "          num_workers=0\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "          self.dev_dataset,\n",
    "          batch_size=self.batch_size,\n",
    "          num_workers=0\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "          self.test_dataset,\n",
    "          batch_size=self.batch_size,\n",
    "          num_workers=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data module instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "data_module = DataModule(df_train_final, df_dev_final, df_test_final, \n",
    "                         tokenizer, batch_size=BATCH_SIZE,max_token_len=MAX_TOKEN_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last four hidden layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextModel(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self,n_classes: int, n_training_steps=None, n_warmup_steps=None):\n",
    "        super().__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(MODEL_NAME, return_dict=True, output_hidden_states=True)\n",
    "        for parameter in self.roberta.parameters():\n",
    "            parameter.require_grad = False\n",
    "        \n",
    "        self.linear_1 = nn.Linear(3072, 1872)\n",
    "        self.linear_2 = nn.Linear(1872, 1172)\n",
    "        self.linear_3 = nn.Linear(1172, 256)\n",
    "        self.classifier = nn.Linear(256, n_classes)\n",
    "        self.n_training_steps = n_training_steps\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        output = self.roberta(input_ids, attention_mask=attention_mask)\n",
    "        #option 1\n",
    "        \n",
    "        #output = self.classifier(output.pooler_output)\n",
    "        #output = torch.softmax(output, dim=1)\n",
    "        #loss = 0\n",
    "        \n",
    "        #option 2\n",
    "        \n",
    "        hidden_states = output[2]\n",
    "        # get last four layers\n",
    "        last_four_layers = [hidden_states[i] for i in (-1, -2, -3, -4)]\n",
    "        # cast layers to a tuple and concatenate over the last dimension\n",
    "        cat_hidden_states = torch.cat(tuple(last_four_layers), dim=-1)\n",
    "        # take the mean of the concatenated vector over the token dimension\n",
    "        output = torch.mean(cat_hidden_states, dim=1)\n",
    "        output = self.linear_1(output)\n",
    "        output = self.linear_2(output)\n",
    "        output = self.linear_3(output)\n",
    "        output = self.classifier(output)\n",
    "        output = torch.softmax(output, dim=1)\n",
    "        loss = 0\n",
    "        \n",
    "        if labels is not None:\n",
    "            labels = labels.flatten() ##\n",
    "            loss = self.criterion(output, labels)\n",
    "        \n",
    "        return loss, output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "\n",
    "        labels = []\n",
    "        predictions = []\n",
    "\n",
    "        for output in outputs:\n",
    "            for out_labels in output[\"labels\"].detach().cpu():\n",
    "                labels.append(out_labels)\n",
    "            for out_predictions in output[\"predictions\"].detach().cpu():\n",
    "                predictions.append(out_predictions)\n",
    "        \n",
    "        labels = torch.stack(labels).int()\n",
    "        predictions = torch.stack(predictions)\n",
    "        pred = torch.argmax(predictions, dim=1)\n",
    "        \n",
    "        train_acc = accuracy(pred, labels, num_classes=3)\n",
    "        #print(\"Label:\", labels)\n",
    "        #print(\"Prediction:\", pred)\n",
    "        print(\"Training Accuracy:\", train_acc)\n",
    "        \n",
    "        label = labels.flatten()\n",
    "        auroc = AUROC(num_classes=3)\n",
    "        auroc = auroc(predictions, label)\n",
    "        print(\"AUROC:\", auroc)\n",
    "\n",
    "    def configure_optimizers(self): #configuring the optimizers\n",
    "\n",
    "        optimizer = AdamW(self.parameters(), lr=2e-5)\n",
    "\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "          optimizer,\n",
    "          num_warmup_steps=self.n_warmup_steps,\n",
    "          num_training_steps=self.n_training_steps\n",
    "\n",
    "        )\n",
    "\n",
    "        return dict(\n",
    "            optimizer=optimizer,\n",
    "            lr_scheduler=dict(\n",
    "                scheduler=scheduler,\n",
    "                interval='step'\n",
    "            )\n",
    "\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch=len(df_train_final) // BATCH_SIZE\n",
    "total_training_steps = steps_per_epoch * N_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1/5 of the training steps as warm-up\n",
    "warmup_steps = total_training_steps // 5\n",
    "warmup_steps, total_training_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextModel(\n",
    "  n_classes=3,\n",
    "  n_warmup_steps=warmup_steps,\n",
    "  n_training_steps=total_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"C:/Users/id301281/NLP/NLU/MELD/RoBERTa\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "    max_epochs=N_EPOCHS,\n",
    "    gpus=1,\n",
    "    progress_bar_refresh_rate=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = TextModel.load_from_checkpoint(\n",
    "  trainer.checkpoint_callback.best_model_path,\n",
    "  n_classes=3\n",
    ")\n",
    "\n",
    "trained_model.eval()\n",
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "val_dataset = Dataset(\n",
    "  df_test_final,\n",
    "  tokenizer,\n",
    "  max_token_len=MAX_TOKEN_COUNT\n",
    ")\n",
    "\n",
    "preds = []\n",
    "labels = []\n",
    "\n",
    "for item in tqdm(val_dataset):\n",
    "    _, prediction = trained_model(\n",
    "        item[\"input_ids\"].unsqueeze(dim=0).to(device),\n",
    "        item[\"attention_mask\"].unsqueeze(dim=0).to(device)\n",
    "    )\n",
    "\n",
    "    preds.append(prediction.flatten())\n",
    "    labels.append(item[\"labels\"].int())\n",
    "\n",
    "preds = torch.stack(preds).detach().cpu()\n",
    "labels = torch.stack(labels).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AUROC per tag\")\n",
    "\n",
    "#for i, name in enumerate(encode_map):\n",
    "label = labels.flatten()\n",
    "auroc = AUROC(num_classes=3)\n",
    "auroc = auroc(preds, label)\n",
    "print(\"AUROC:\", auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = preds.numpy()\n",
    "y_pred = torch.argmax(preds, dim=1)\n",
    "y_test = labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=encode_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(confusion_matrix):\n",
    "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
    "  plt.ylabel('True sentiment')\n",
    "  plt.xlabel('Predicted sentiment');\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(cm, index=encode_map, columns=encode_map)\n",
    "show_confusion_matrix(df_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing test predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = TextModel.load_from_checkpoint(\n",
    "  trainer.checkpoint_callback.best_model_path,\n",
    "  n_classes=3\n",
    ")\n",
    "\n",
    "trained_model.eval()\n",
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last four hidden layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "test_dataset = Dataset(\n",
    "  df_test_final,\n",
    "  tokenizer,\n",
    "  max_token_len=MAX_TOKEN_COUNT\n",
    ")\n",
    "\n",
    "test_predictions = { \"fileID_roberta_lfl\": [], \"Negative_roberta_lfl\" : [], \"Neutral_roberta_lfl\" : [], \"Positive_roberta_lfl\" : [], \"predicted_roberta_lfl\": [], \"actual_roberta_lfl\": []}\n",
    "\n",
    "\n",
    "for item in tqdm(test_dataset):\n",
    "    _, prediction = trained_model(\n",
    "        item[\"input_ids\"].unsqueeze(dim=0).to(device),\n",
    "        item[\"attention_mask\"].unsqueeze(dim=0).to(device)\n",
    "    )\n",
    "\n",
    "    pred = prediction.flatten().detach().cpu().numpy()\n",
    "    pred2 = prediction.flatten()\n",
    "    pred3 = torch.argmax(pred2).squeeze().tolist()\n",
    "    test_predictions[\"predicted_roberta_lfl\"].append(pred3)\n",
    "    test_predictions[\"Negative_roberta_lfl\"].append(pred[0])\n",
    "    test_predictions[\"Neutral_roberta_lfl\"].append(pred[1])\n",
    "    test_predictions[\"Positive_roberta_lfl\"].append(pred[2])\n",
    "    test_predictions[\"actual_roberta_lfl\"].append(item[\"labels\"].squeeze(-1).numpy())\n",
    "    test_predictions[\"fileID_roberta_lfl\"].append(item[\"FileID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=test_predictions)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving to csv\n",
    "df.to_csv(r\"C:/Data/Sentiment Analysis/MELD/ensemble preds/roberta_text/test_preds_roberta_lfl_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-GoogleSTT]",
   "language": "python",
   "name": "conda-env-.conda-GoogleSTT-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
