{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the data here = https://affective-meld.github.io/\n",
    "df_train_final = pd.read_csv(r\"C:/Data/Sentiment Analysis/MELD/Processed/Processed_final/v2/train.csv\") #please put your path\n",
    "df_dev_final = pd.read_csv(r\"C:/Data/Sentiment Analysis/MELD/Processed/Processed_final/v2/dev.csv\") #please put your path\n",
    "df_test_final = pd.read_csv(r\"C:/Data/Sentiment Analysis/MELD/Processed/Processed_final/v2/test.csv\") #please put your path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train_final.shape, df_dev_final.shape,df_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final['sentiment'] = df_train_final['sentiment'].astype('category')\n",
    "encode_map = {'negative': 0,'neutral': 1,'positive': 2}\n",
    "df_train_final['sentiment'].replace(encode_map, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev_final['sentiment'] = df_dev_final['sentiment'].astype('category')\n",
    "encode_map = {'negative': 0,'neutral': 1,'positive': 2}\n",
    "df_dev_final['sentiment'].replace(encode_map, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_final['sentiment'] = df_test_final['sentiment'].astype('category')\n",
    "encode_map = {'negative': 0,'neutral': 1,'positive': 2}\n",
    "df_test_final['sentiment'].replace(encode_map, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_final = df_train_final.rename(columns={\"name\": \"file_ID\"})\n",
    "df_dev_final = df_dev_final.rename(columns={\"name\": \"file_ID\"})\n",
    "df_test_final = df_test_final.rename(columns={\"name\": \"file_ID\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_train_final, df_dev_final, df_test_final]\n",
    "combine = pd.concat(frames)\n",
    "all_data = combine.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head(5) #neg=0, neu=1, pos=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_COLUMNS = all_data.columns.tolist()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKEN_COUNT = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'roberta-base'\n",
    "tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        tokenizer: RobertaTokenizer,\n",
    "        max_token_len: int = 60\n",
    "    ):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        data_row = self.data.iloc[index]\n",
    "        \n",
    "        Utterance = data_row.transcription\n",
    "        labels = data_row[LABEL_COLUMNS] ##all\n",
    "        fileID = data_row.file_ID\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            Utterance,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_token_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        return dict(\n",
    "            Utterance=Utterance,\n",
    "            input_ids=encoding[\"input_ids\"].flatten(),\n",
    "            attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "            labels=labels,\n",
    "            FileID=fileID\n",
    "\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(batch_size, max_token_len=60):\n",
    "    \n",
    "    train_dataset = Dataset(\n",
    "    df_train_final,\n",
    "    tokenizer,\n",
    "    max_token_len)\n",
    "        \n",
    "    train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0)\n",
    "    \n",
    "    dev_dataset = Dataset(\n",
    "    df_dev_final,\n",
    "    tokenizer,\n",
    "    max_token_len)\n",
    "        \n",
    "    dev_loader = DataLoader(\n",
    "    dev_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0)\n",
    "    \n",
    "    test_dataset = Dataset(\n",
    "    df_test_final,\n",
    "    tokenizer,\n",
    "    max_token_len)\n",
    "        \n",
    "    test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0)\n",
    "    \n",
    "    return train_loader, dev_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_Device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEmbeddingModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(MODEL_NAME, return_dict=True, output_hidden_states=True).to(device)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        output = self.roberta(input_ids, attention_mask=attention_mask)\n",
    "        #output = output.pooler_output\n",
    "        \n",
    "        #return output\n",
    "        \n",
    "        hidden_states = output[2]\n",
    "        # get last four layers\n",
    "        last_four_layers = [hidden_states[i] for i in (-1, -2, -3, -4)]\n",
    "        # cast layers to a tuple and concatenate over the last dimension\n",
    "        cat_hidden_states = torch.cat(tuple(last_four_layers), dim=-1)\n",
    "        # take the mean of the concatenated vector over the token dimension\n",
    "        cat_sentence_embedding = torch.mean(cat_hidden_states, dim=1)\n",
    "        \n",
    "        return cat_sentence_embedding\n",
    "    \n",
    "model = TextEmbeddingModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting train embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(df_train_final,tokenizer,max_token_len=MAX_TOKEN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "embeddings = {\"embeddings\" : [], \"labels\": [], \"fileID\": []}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in train_dataset:\n",
    "        counter += 1\n",
    "        input_ids = torch.unsqueeze(i[\"input_ids\"],0).to(device)\n",
    "        attention_mask = torch.unsqueeze(i[\"attention_mask\"],0).to(device)\n",
    "        labels = i['labels']\n",
    "        fileID = i['FileID']\n",
    "    \n",
    "        results = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        #results.to(cpu_device)\n",
    "    \n",
    "        embeddings[\"embeddings\"].append(results)\n",
    "        embeddings[\"labels\"].append(labels)\n",
    "        embeddings[\"fileID\"].append(fileID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and loading tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:/Data/Sentiment Analysis/MELD/Processed/Processed_final/embeddings_v2/train.pt\"\n",
    "torch.save(embeddings, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embgs = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting dev embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = Dataset(df_dev_final,tokenizer,max_token_len=MAX_TOKEN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "embeddings = {\"embeddings\" : [], \"labels\": [], \"fileID\": []}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in dev_dataset:\n",
    "        counter += 1\n",
    "        input_ids = torch.unsqueeze(i[\"input_ids\"],0).to(device)\n",
    "        attention_mask = torch.unsqueeze(i[\"attention_mask\"],0).to(device)\n",
    "        labels = i['labels']\n",
    "        fileID = i['FileID']\n",
    "    \n",
    "        results = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "        embeddings[\"embeddings\"].append(results)\n",
    "        embeddings[\"labels\"].append(labels)\n",
    "        embeddings[\"fileID\"].append(fileID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and loading tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:/Data/Sentiment Analysis/MELD/Processed/Processed_final/embeddings_v2/dev.pt\"\n",
    "torch.save(embeddings, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embgs = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting test embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Dataset(df_test_final,tokenizer,max_token_len=MAX_TOKEN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "embeddings = {\"embeddings\" : [], \"labels\": [], \"fileID\": []}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in test_dataset:\n",
    "        counter += 1\n",
    "        input_ids = torch.unsqueeze(i[\"input_ids\"],0).to(device)\n",
    "        attention_mask = torch.unsqueeze(i[\"attention_mask\"],0).to(device)\n",
    "        labels = i['labels']\n",
    "        fileID = i['FileID']\n",
    "    \n",
    "        results = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "        embeddings[\"embeddings\"].append(results)\n",
    "        embeddings[\"labels\"].append(labels)\n",
    "        embeddings[\"fileID\"].append(fileID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and loading tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:/Data/Sentiment Analysis/MELD/Processed/Processed_final/embeddings_v2/test.pt\"\n",
    "torch.save(embeddings, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embgs = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = Dataset(\n",
    "  df_train_final,\n",
    "  tokenizer,\n",
    "  max_token_len=MAX_TOKEN_COUNT\n",
    ")\n",
    "\n",
    "encoding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoding[0][\"input_ids\"].size())\n",
    "print(type(encoding[0][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.unsqueeze(encoding[0][\"input_ids\"],0).to(device)\n",
    "attention_mask = torch.unsqueeze(encoding[0][\"attention_mask\"],0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embeddings = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "print(embeddings)\n",
    "print(type(embeddings))\n",
    "print(len(embeddings))\n",
    "#print(embeddings.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last four layers embeddings example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = embeddings[2]\n",
    "print(len(hidden_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get last four layers\n",
    "last_four_layers = [hidden_states[i] for i in (-1, -2, -3, -4)]\n",
    "# cast layers to a tuple and concatenate over the last dimension\n",
    "cat_hidden_states = torch.cat(tuple(last_four_layers), dim=-1)\n",
    "print(cat_hidden_states.size())\n",
    "\n",
    "# take the mean of the concatenated vector over the token dimension\n",
    "cat_sentence_embedding = torch.mean(cat_hidden_states, dim=1).squeeze()\n",
    "print(cat_sentence_embedding)\n",
    "print(cat_sentence_embedding.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting train embeddings {last four layers}: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(df_train_final,tokenizer,max_token_len=MAX_TOKEN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "embeddings = {\"embeddings\" : [], \"labels\": [], \"fileID\": []}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in train_dataset:\n",
    "        counter += 1\n",
    "        input_ids = torch.unsqueeze(i[\"input_ids\"],0).to(device)\n",
    "        attention_mask = torch.unsqueeze(i[\"attention_mask\"],0).to(device)\n",
    "        labels = i['labels']\n",
    "        fileID = i['FileID']\n",
    "    \n",
    "        results = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "        embeddings[\"embeddings\"].append(results)\n",
    "        embeddings[\"labels\"].append(labels)\n",
    "        embeddings[\"fileID\"].append(fileID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings[\"embeddings\"][0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and loading tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:/Data/Sentiment Analysis/MELD/Processed/Processed_final/embeddings_v2/train_lfl.pt\"\n",
    "torch.save(embeddings, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embgs = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting dev embeddings {last four layers}:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = Dataset(df_dev_final,tokenizer,max_token_len=MAX_TOKEN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "embeddings = {\"embeddings\" : [], \"labels\": [], \"fileID\": []}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in dev_dataset:\n",
    "        counter += 1\n",
    "        input_ids = torch.unsqueeze(i[\"input_ids\"],0).to(device)\n",
    "        attention_mask = torch.unsqueeze(i[\"attention_mask\"],0).to(device)\n",
    "        labels = i['labels']\n",
    "        fileID = i['FileID']\n",
    "    \n",
    "        results = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "        embeddings[\"embeddings\"].append(results)\n",
    "        embeddings[\"labels\"].append(labels)\n",
    "        embeddings[\"fileID\"].append(fileID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings[\"embeddings\"][0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and loading tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:/Data/Sentiment Analysis/MELD/Processed/Processed_final/embeddings_v2/dev_lfl.pt\"\n",
    "torch.save(embeddings, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embgs = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting test embeddings {last four layers}: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Dataset(df_test_final,tokenizer,max_token_len=MAX_TOKEN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "embeddings = {\"embeddings\" : [], \"labels\": [], \"fileID\": []}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in test_dataset:\n",
    "        counter += 1\n",
    "        input_ids = torch.unsqueeze(i[\"input_ids\"],0).to(device)\n",
    "        attention_mask = torch.unsqueeze(i[\"attention_mask\"],0).to(device)\n",
    "        labels = i['labels']\n",
    "        fileID = i['FileID']\n",
    "    \n",
    "        results = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "        embeddings[\"embeddings\"].append(results)\n",
    "        embeddings[\"labels\"].append(labels)\n",
    "        embeddings[\"fileID\"].append(fileID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings[\"embeddings\"][0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and loading tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:/Data/Sentiment Analysis/MELD/Processed/Processed_final/embeddings_v2/test_lfl.pt\"\n",
    "torch.save(embeddings, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embgs = torch.load(PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-GoogleSTT]",
   "language": "python",
   "name": "conda-env-.conda-GoogleSTT-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
